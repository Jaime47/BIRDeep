{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.optimizers import legacy as legacy_optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import regularizers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.load(\"class_names.npy\", allow_pickle=True).item()\n",
    "\n",
    "train_df = pd.read_csv(\"train_images.csv\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "train_images = os.path.join(current_dir, 'train_images')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    img_filename = row['image_path'][1:]  \n",
    "    img_path = os.path.join(train_images, img_filename)\n",
    "    label = row['label'] - 1\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (299, 299))\n",
    "    img = img / 255.0\n",
    "\n",
    "    X.append(img)\n",
    "    y.append(label)\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPERPARAMETER TUNING\n",
    "\n",
    "def create_model(optimizer=legacy_optimizers.Adam(lr=0.001), neurons=256, reg_strength=0.01, learning_rate=0.001):\n",
    " \n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons, activation='relu', kernel_regularizer=regularizers.l2(reg_strength)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(len(class_names), activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'neurons': [512], # 128, 256\n",
    "    'reg_strength': [0.01, 0.001],\n",
    "    'learning_rate': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for neurons in param_grid['neurons']:\n",
    "    for reg_strength in param_grid['reg_strength']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "           \n",
    "            model = create_model(neurons=neurons, reg_strength=reg_strength, learning_rate=learning_rate) \n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(X_train, y_train, epochs=1, batch_size=32, verbose=1, validation_data=(X_val, y_val))\n",
    "            val_accuracy = history.history['val_accuracy'][0]\n",
    "\n",
    "            if val_accuracy > best_score:\n",
    "                best_score = val_accuracy\n",
    "                best_params = {'neurons': neurons, 'reg_strength': reg_strength, 'learning_rate': learning_rate}\n",
    "                print(\"Validation accuracy: {:.4f} for {}\".format(val_accuracy, best_params))\n",
    "\n",
    "print(\"Best validation accuracy: {:.4f} using {}\".format(best_score, best_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dense(len(class_names), activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_val, y_val), callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model20.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model20.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = pd.read_csv(\"test_images_path.csv\")\n",
    "current_dir = os.getcwd()\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_images = os.path.join(current_dir, 'test_images')  \n",
    "\n",
    "X_test = []\n",
    "\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    img_filename = row['image_path'][1:]  \n",
    "    img_path = os.path.join(test_images, img_filename)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = cv2.resize(img, (299, 299))\n",
    "    img = img / 255.0\n",
    "\n",
    "    X_test.append(img)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "test_df['label'] = predicted_labels\n",
    "\n",
    "selected_columns = ['id', 'label']\n",
    "test_df_selected = test_df[selected_columns]\n",
    "\n",
    "current_datetime = datetime.datetime.now()\n",
    "timestamp = current_datetime.strftime(\"%Y%m%d_%H%M\")\n",
    "file_name = f\"submission_{timestamp}.csv\"\n",
    "\n",
    "submissions_folder = os.path.join(current_dir, 'submissions')  \n",
    "\n",
    "file_path = os.path.join(submissions_folder, file_name)\n",
    "\n",
    "test_df_selected.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
